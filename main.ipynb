{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d76c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import path\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gdown\n",
    "from exif import Image\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import os\n",
    "from haversine import haversine, Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af62c76",
   "metadata": {},
   "source": [
    "# Project scope üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7af5ea",
   "metadata": {},
   "source": [
    "**Mi camino** aims to be a little project for tracking my daily progress during my *Camino de Santiago* on bike. It will consist of several Python scripts that perform the following actions:\n",
    "\n",
    "- Download all files in a *Google Drive* folder (gpx files and pictures) at set intervals.\n",
    "- Parse the gpx files.\n",
    "- Otain the location of the pictures using the metadata.\n",
    "- Display the latest progress (parsed gpx files) on a map via *Folium*.\n",
    "- Send the pictures to my *Raspberry* and display them on the map with a marker on the point they were taken.\n",
    "- Display the current progress (km/elevation).\n",
    "\n",
    "For my convenience I chose to use a *Google Drive* folder to store all gpx files and pictures that I want to upload during the route. This way I can limit the data uploads to once/twice a day and I can keep the scripts *relatively* simple, with just a few lines of web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2bd37",
   "metadata": {},
   "source": [
    "## Downloading data from *Google Drive*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6054405",
   "metadata": {},
   "source": [
    "*Google* provides an API to interact with *Drive*, but since I only want to download a few files at a time and perform no uploads whatsoever I found a much simpler way to do so via the *gdown* library.\n",
    "\n",
    "Once you have downloaded the folder it's simply a matter of accessing it using our beloved *Selenium*. Please notice that I'm not using the regular *chromedriver* but a library that automatically downloads and runs it for you, eliminating the risk of an out-of-date chromedriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613eab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For security purposes it's good practice to store private links in txt files and add the to the gitignore\n",
    "\n",
    "link = open('download_link.txt','r').readline() # Reading the file containing the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88da613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\User\\\\micamino\\\\camino\\\\Primera_etapa_Pirinexus.gpx',\n",
       " 'C:\\\\Users\\\\User\\\\micamino\\\\camino\\\\PXL_20220629_145708603.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the folder using gdown\n",
    "\n",
    "url = link\n",
    "gdown.download_folder(url, quiet=True, use_cookies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414718ef",
   "metadata": {},
   "source": [
    "## Unzipping the file and reading its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499f70a",
   "metadata": {},
   "source": [
    "The driver now contains both types of files that we'll encounter, *gpx* files and pictures. Let's filter the filenames in both categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a008ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/User/micamino/camino/Primera_etapa_Pirinexus.gpx')]\n",
      "[WindowsPath('C:/Users/User/micamino/camino/PXL_20220629_145708603.jpg')]\n"
     ]
    }
   ],
   "source": [
    "directory = r'C:\\Users\\User\\micamino\\camino' # Out download folder\n",
    "files = Path(directory).glob('*') # Using all files in the folder as input\n",
    "files = list(files)\n",
    "\n",
    "gpx = [] # We'll hold gpx file paths\n",
    "images = [] # Same for images\n",
    "for file in files:\n",
    "    if '.jpg' in str(file): # Filtering by filename\n",
    "        images.append(file)\n",
    "    elif '.gpx' in str(file):\n",
    "        gpx.append(file)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(gpx)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c1374",
   "metadata": {},
   "source": [
    "## Image processing: obtaining coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5facbbcb",
   "metadata": {},
   "source": [
    "Since we want to display on the map the images with a marker on the point they were taken, we will need to extract their coordinates. This can be achieved via the *EXIF* data embedded in each picture. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8febca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's open the image\n",
    "\n",
    "img_path = images[0] # Using the path we just obtained\n",
    "with open(img_path, 'rb') as src:\n",
    "    img = Image(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce444cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 24.0, 8.57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's access its longitude\n",
    "\n",
    "img.gps_longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bd066",
   "metadata": {},
   "source": [
    "As we can see, the longitude and latitude are in degrees, minutes and seconds. We'll need to use a little function to convert those coordinates to decimal degrees, as well as making the process more streamlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd229c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define a function that simply converts the coordinates to decimal degrees.\n",
    "# We'll have to take into account the orientation (ref), because the result will vary whether it's facing south or west.\n",
    "\n",
    "def converter(coords, ref):\n",
    "    ####################\n",
    "    #Input: coordinates and ref (orientation) of the picture, as expressed by the parser\n",
    "    # Output: if there's coordinates, returns them in decimal degrees.\n",
    "    ####################\n",
    "    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600 # Converting to decimal degrees\n",
    "    if ref == 'S' or ref == 'W':\n",
    "        decimal_degrees = -decimal_degrees # Changing sign if it's facing south or west\n",
    "    return decimal_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ac50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's incorporate it into a new function that will return the coordinates if there's any, and simply\n",
    "# return False if there aren't. This way we can use the same function to know if an image has coordinates\n",
    "# and also retrieve them.\n",
    "\n",
    "def coordinates(image_path):\n",
    "    ####################\n",
    "    #Input: path of an image\n",
    "    # Output: coordinates if there's any, False in any other case\n",
    "    ####################\n",
    "    with open(img_path, 'rb') as src: # Accessing the image \n",
    "        img = Image(src)    \n",
    "    if img.has_exif:\n",
    "        try:\n",
    "            img.gps_longitude\n",
    "            coords = (converter(img.gps_latitude, # Using our previously defined function\n",
    "                      img.gps_latitude_ref),\n",
    "                      converter(img.gps_longitude,\n",
    "                      img.gps_longitude_ref))\n",
    "        except:\n",
    "            return False # Returning False if the process fails at any point\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "    return coords # Returning the coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49524363",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf898a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.65405277777778, 2.4023805555555553)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try it out with the image we downloaded\n",
    "\n",
    "coordinates(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232f152",
   "metadata": {},
   "source": [
    "# Flowchart üåä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9add40",
   "metadata": {},
   "source": [
    "The tool behind the **mi Camino** webpage will have two main components: the main loop and the map creator.\n",
    "\n",
    "The main loop will check every *xx* minutes if there's new files (be it gpx or images) in the shared folder, and process them accordingly.\n",
    "\n",
    "The map creator will use the files generated or updated by the main loop to create a new map, which will be displayed in the website.\n",
    "\n",
    "I will now proceed to explain every part in detail, as well as the file system I'll have in place:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3be405",
   "metadata": {},
   "source": [
    "## File system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0364b",
   "metadata": {},
   "source": [
    "The *gpx* files will stay in the original folder, since they only need to be parsed once. All images will be moved to a separate **img** folder, where they will be indexed and accessed by the website (via **Nginx**).\n",
    "\n",
    "Both the main loop and the map creator will use and access several *csv* files, which will mainly act as lightweight dataframe holders. Using *pkl* files was also considered, but it wasn't worth the hassle since read/write speeds aren't critical in our use case. \n",
    "\n",
    "The *csv* files that will be used consist of the following:\n",
    "\n",
    "- **file_log.csv**: contains the original path of every processed file, to prevent duplicates.\n",
    "\n",
    "- **images.csv**: contains both the filepath and coordinates of every picture.\n",
    "\n",
    "- **route.csv**: holds the parsed gpx files of the route I've cycled until that point. Every row is a point, as per gpx standard.\n",
    "\n",
    "- **camino.csv**: the original Camino de Santiago route, to be more specific the french Way. Since every day I'll be traversing part of this route, it will get shorter accordingly. It will always be the original route - the contents of *route.csv*.\n",
    "\n",
    "- **markers.csv**: it will contain information (coordinates, text, html code...) necessary to create map markers when necessary. For example, there will be a marker both at the start/end of the route and at the end of every day's journey, something vital to track overall progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db26a4",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc853a8",
   "metadata": {},
   "source": [
    "The main loop will go through the following steps:\n",
    "\n",
    "**1.** Download all files from the shared folder.\n",
    "\n",
    "**2.** Check filenames against a file log (*file_log.csv*) to detect duplicates.\n",
    "\n",
    "**3.** If there's no new files, the loop will stop at this point. If there are, it will continue.\n",
    "\n",
    "**4.** New files are added to the file log, marking them as processed.\n",
    "\n",
    "**5.** Move images to *img* folder. Store their file paths and image coordinates as a new row in *images.csv*.\n",
    "\n",
    "**6.** Parse gpx files and add the new points to *route.csv*.\n",
    "\n",
    "**7.** Find the closest point to the route for the track in *camino.csv*, which contains the original route from start to finish. Delete the necessary rows so that the remaining route is the original route - distance travelled.\n",
    "\n",
    "**8.** If the date of the parsed *gpx* files is different from the last gpx, a new entry will be created in *markers.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332521ba",
   "metadata": {},
   "source": [
    "## Map creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7c5d5",
   "metadata": {},
   "source": [
    "The map creator will perform the following actions:\n",
    "\n",
    "**1.** Create a new map with bounds (size auto-adjusts).\n",
    "\n",
    "**2.** Plot both routes (*route.csv* and *camino.csv*).\n",
    "\n",
    "**3.** Create and display a marker for every image in *images.csv*.\n",
    "\n",
    "**4.** Create and display a marker for every row in *markers.csv*.\n",
    "\n",
    "**5.** Save the resulting map with the required filename. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e319a17",
   "metadata": {},
   "source": [
    "Now that the basic logic behind our project has been established, let's get to business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416528a",
   "metadata": {},
   "source": [
    "# Development üîß  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f87b3",
   "metadata": {},
   "source": [
    "Let's begin by creating and saving the *csv* files we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e10d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_log = pd.DataFrame(columns=['filepath'])\n",
    "file_log.to_csv('file_log.csv', index=False)\n",
    "\n",
    "images = pd.DataFrame(columns=['filepath', 'coords'])\n",
    "images.to_csv('images.csv', index=False)\n",
    "\n",
    "route = pd.DataFrame(columns=['coords','alt', 'time'])\n",
    "route.to_csv('route.csv', index=False)\n",
    "\n",
    "camino = pd.DataFrame(columns=['coords','alt', 'time'])\n",
    "camino.to_csv('camino.csv', index=False)\n",
    "\n",
    "markers = pd.DataFrame(columns=['coords', 'text', 'html', 'icon', 'color'])\n",
    "markers.to_csv('markers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cdb71",
   "metadata": {},
   "source": [
    "Now we have the empty *csv* files, which is fine for all of them except *camino.csv*, which should hold the parsed *gpx* file containing the whole route. I won't be following it all the time, but it's a good guideline.\n",
    "\n",
    "In this step we'll parse the *gpx* file and store its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "523280ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'camino.gpx' # The gpx file we need to parse\n",
    "gpx_file = open(filename, 'r', encoding='utf-8') # Opening it, we might encounter encoding issues\n",
    "gpx = gpxpy.parse(gpx_file) #Parsing the file\n",
    "data = gpx.tracks[0].segments[0].points # Extracting all data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519811ec",
   "metadata": {},
   "source": [
    "Now we'll use the latitude/longitude/elevation attributes to extract the coordinates from each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86843ba6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coords = [] #Storing the coordinates\n",
    "alt = [] # Same for the elevation\n",
    "time = []\n",
    "\n",
    "for point in data:\n",
    "    point_coords = (point.latitude,point.longitude) # Obtaining the coordinates from every point\n",
    "    point_alt = point.elevation\n",
    "    point_time = point.time\n",
    "    coords.append(point_coords) #Appending it to the list\n",
    "    alt.append(point_alt)\n",
    "    time.append(point_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a46f3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>alt</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(43.010221, -1.319525)</td>\n",
       "      <td>953.053</td>\n",
       "      <td>2017-04-29 05:41:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(43.009372, -1.319931)</td>\n",
       "      <td>951.804</td>\n",
       "      <td>2017-04-29 05:43:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(43.009108, -1.319748)</td>\n",
       "      <td>950.914</td>\n",
       "      <td>2017-04-29 05:44:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(43.00853, -1.319887)</td>\n",
       "      <td>947.508</td>\n",
       "      <td>2017-04-29 05:45:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(43.007335, -1.319483)</td>\n",
       "      <td>942.526</td>\n",
       "      <td>2017-04-29 05:52:57+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coords      alt                      time\n",
       "0  (43.010221, -1.319525)  953.053 2017-04-29 05:41:48+00:00\n",
       "1  (43.009372, -1.319931)  951.804 2017-04-29 05:43:56+00:00\n",
       "2  (43.009108, -1.319748)  950.914 2017-04-29 05:44:50+00:00\n",
       "3   (43.00853, -1.319887)  947.508 2017-04-29 05:45:16+00:00\n",
       "4  (43.007335, -1.319483)  942.526 2017-04-29 05:52:57+00:00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store those values inside the corresponding csv.\n",
    "\n",
    "df = pd.read_csv('camino.csv')\n",
    "\n",
    "df['coords'] = coords\n",
    "df['alt'] = alt\n",
    "df['time'] = time\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9246bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only thing left to do is save the csv.\n",
    "\n",
    "df.to_csv('camino.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fc0f9",
   "metadata": {},
   "source": [
    "### Detecting new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c95e75",
   "metadata": {},
   "source": [
    "The first step in the main loop will be downloading the files in the shared folder and checking for new files. To perform this task we'll re-use the code at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdec2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader():\n",
    "    ####################\n",
    "    # Input: none required, but \"url\" must point to a valid GDrive folder\n",
    "    # Output: dictionary containing a list for gpx filenames, same for images\n",
    "    ####################\n",
    "    try:\n",
    "        link = open('download_link.txt','r').readline()\n",
    "        url = link\n",
    "        gdown.download_folder(url, quiet=True, use_cookies=False)\n",
    "\n",
    "        directory = r'C:\\Users\\User\\micamino\\camino' # Out download folder\n",
    "\n",
    "        files = Path(directory).glob('*') # Using all files in the folder as input\n",
    "        files = list(files)\n",
    "\n",
    "        gpx = []\n",
    "        images = []\n",
    "        for file in files:\n",
    "            if '.jpg' in str(file):\n",
    "                images.append(file)\n",
    "            elif '.gpx' in str(file):\n",
    "                gpx.append(file)\n",
    "            else:\n",
    "                pass\n",
    "        print('downloader OK')\n",
    "        return {'gpx': gpx, 'images': images} # The function returns a dictionary of lists, with all filenames\n",
    "    except:\n",
    "        print('downloader FAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34af0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloader OK\n",
      "[WindowsPath('C:/Users/User/micamino/camino/Primera_etapa_Pirinexus.gpx')]\n",
      "[WindowsPath('C:/Users/User/micamino/camino/PXL_20220629_145708603.jpg')]\n"
     ]
    }
   ],
   "source": [
    "files = downloader() # Running the function we just created\n",
    "\n",
    "print(files['gpx']) # Accessing the images\n",
    "print(files['images']) #Accessing gpx files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26724162",
   "metadata": {},
   "source": [
    "### Handling images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb6f97",
   "metadata": {},
   "source": [
    "Once we've downloaded \n",
    "\n",
    "Now let's test how can we move images to the *img* folder. For this purpose we'll be using the library *shutil*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58333944",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = os.getcwd() + r'/camino/' # Folder where all files are downloaded, takes into account current dir\n",
    "destination_folder = os.getcwd() + r'/img/' # Output image folder\n",
    " \n",
    "allfiles = os.listdir(source_folder)\n",
    " \n",
    "for file in allfiles:\n",
    "    if '.jpg' in file: # Moving just jpg images\n",
    "        source = source_folder + file\n",
    "        destination = destination_folder + file\n",
    "        shutil.move(source , destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937216a4",
   "metadata": {},
   "source": [
    "Let's add this functionality to our *downloader* function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0fe4b7",
   "metadata": {},
   "source": [
    "Since we will need to update *camino.csv* every time that a new gpx file is processed, we'll have to test the procedure first. We will be using haversine distance calculations to find the nearest point between *route.csv* and *camino.csv*, and then cutting the *camino.csv* at the desired point.\n",
    "\n",
    "To perform the testing I've temporarily filled *route.csv* with partial data from *camino.csv*, representing a first day's ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "027930c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading both files\n",
    "camino = pd.read_csv('camino.csv')\n",
    "route = pd.read_csv('route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ce77a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568.3330277885041"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the closest point from the end of the ride (last value of \"route\") to the end of the original route(camino).\n",
    "# For this purpose we'll use the haversine library. Its name is pretty self-explanatory.\n",
    "\n",
    "point_a = eval(route['coords'].iloc[-1]) #We'll need to use eval for the coordinates so that they are read as a tuple.\n",
    "point_b = eval(camino['coords'].iloc[-1])\n",
    "\n",
    "haversine(point_a, point_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee74c5",
   "metadata": {},
   "source": [
    "Now let's define a function that finds the minimum distance between the end of *route.csv* and any point of *camino.csv*.\n",
    "It will then shorten the *camino.csv* file accordingly, so that the last point is the closest point to the end of our current route. In other words: the *camino* file will contain **the route that we haven't travelled yet**.\n",
    "\n",
    "**NOTE:** to perform this very same process in other projects I've used vectorized functions applied on an array that contains the coordinates, but since the data volume for this project is *very* low (a single csv at a time) it's not worth the hassle, and I'd rather spend a few more CPU cycles on the calculation than generate potential issues with more dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bec9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_updater(route_csv, camino_csv):\n",
    "    ####################\n",
    "    # Input: route and camino csv files.\n",
    "    # Output: modifies and saves camino.csv\n",
    "    ####################\n",
    "    try:\n",
    "        route = pd.read_csv('route.csv') #Loading the csv files.\n",
    "        camino = pd.read_csv('camino.csv')\n",
    "\n",
    "        min_distance_index = '' # Here we'll hold the index of the minimum distance point.\n",
    "        distance_b = '800' # This value will be replaced every time a lower value is found.\n",
    "\n",
    "        for row in range(len(camino)): # Iterating through the dataframe (painful but necessary).\n",
    "            distance_a = haversine(eval(route['coords'].iloc[-1]), eval(camino['coords'].iloc[row])) # Calculating distance.\n",
    "            if float(distance_a) < float(distance_b): # If the distance is lower than the current one, replace it.\n",
    "                distance_b = distance_a\n",
    "                min_distance_index = row # Also replace the value of the row (index).\n",
    "\n",
    "        camino_shortened = camino[min_distance_index:] # Using the index to crop the csv.\n",
    "        camino_shortened = camino_shortened.reset_index(drop=True) # Resetting the index.\n",
    "        camino_shortened.to_csv('camino.csv', index=False) # Saving the updated camino.csv\n",
    "        \n",
    "        print('camino_updater OK') # Printing status message.\n",
    "    except:\n",
    "        print('camino_updater FAIL')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8c4e6",
   "metadata": {},
   "source": [
    "The next step will be creating a function that performs the following actions:\n",
    "\n",
    "- Downloads the content from the shared folder via *downloader* function.\n",
    "- Compares the downloaded files with the names found in *file_log.csv*.\n",
    "- If there's no new files it stops and returns *False*.\n",
    "- If there's new files it will perform the following:\n",
    "    - Add image data to *images.csv* and move the files to the *img* folder.\n",
    "    - Process gpx files, updating both *route.csv* and *camino.csv*.\n",
    "    - Add the new files to *file_log.csv*.\n",
    "    - Return *True*, so that we can use this output to know when a new map needs to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da533935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
