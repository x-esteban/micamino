{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d76c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re \n",
    "import path\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gdown\n",
    "from exif import Image\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import os\n",
    "from haversine import haversine, Unit\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af62c76",
   "metadata": {},
   "source": [
    "# Project scope üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7af5ea",
   "metadata": {},
   "source": [
    "**Mi camino** aims to be a little project for tracking my daily progress during my *Camino de Santiago* on bike. It will consist of several Python scripts that perform the following actions:\n",
    "\n",
    "- Download all files in a *Google Drive* folder (gpx files and pictures) at set intervals.\n",
    "- Parse the gpx files.\n",
    "- Otain the location of the pictures using the metadata.\n",
    "- Display the latest progress (parsed gpx files) on a map via *Folium*.\n",
    "- Send the pictures to my *Raspberry* and display them on the map with a marker on the point they were taken.\n",
    "- Display the current progress (km/elevation).\n",
    "\n",
    "For my convenience I chose to use a *Google Drive* folder to store all gpx files and pictures that I want to upload during the route. This way I can limit the data uploads to once/twice a day and I can keep the scripts *relatively* simple, with just a few lines of web scraping.\n",
    "\n",
    "Before we create the necessary functions we'll need to test some basic functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2bd37",
   "metadata": {},
   "source": [
    "## Downloading data from *Google Drive*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6054405",
   "metadata": {},
   "source": [
    "*Google* provides an API to interact with *Drive*, but since I only want to download a few files at a time and perform no uploads whatsoever I found a much simpler way to do so via the *gdown* library.\n",
    "\n",
    "Once you have downloaded the folder it's simply a matter of accessing it using our beloved *Selenium*. Please notice that I'm not using the regular *chromedriver* but a library that automatically downloads and runs it for you, eliminating the risk of an out-of-date chromedriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613eab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For security purposes it's good practice to store private links in txt files and add the to the gitignore\n",
    "\n",
    "link = open('download_link.txt','r').readline() # Reading the file containing the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88da613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\User\\\\micamino\\\\camino\\\\Primera_etapa_Pirinexus.gpx',\n",
       " 'C:\\\\Users\\\\User\\\\micamino\\\\camino\\\\PXL_20220629_145708603.jpg']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the folder using gdown\n",
    "\n",
    "url = link\n",
    "gdown.download_folder(url, quiet=True, use_cookies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414718ef",
   "metadata": {},
   "source": [
    "## Unzipping the file and reading its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499f70a",
   "metadata": {},
   "source": [
    "The driver now contains both types of files that we'll encounter, *gpx* files and pictures. Let's filter the filenames in both categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a008ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/User/micamino/camino/Primera_etapa_Pirinexus.gpx')]\n",
      "[WindowsPath('C:/Users/User/micamino/camino/PXL_20220629_145708603.jpg')]\n"
     ]
    }
   ],
   "source": [
    "directory = r'C:\\Users\\User\\micamino\\camino' # Out download folder\n",
    "files = Path(directory).glob('*') # Using all files in the folder as input\n",
    "files = list(files)\n",
    "\n",
    "gpx = [] # We'll hold gpx file paths\n",
    "images = [] # Same for images\n",
    "for file in files:\n",
    "    if '.jpg' in str(file): # Filtering by filename\n",
    "        images.append(file)\n",
    "    elif '.gpx' in str(file):\n",
    "        gpx.append(file)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(gpx)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c1374",
   "metadata": {},
   "source": [
    "## Image processing: obtaining coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5facbbcb",
   "metadata": {},
   "source": [
    "Since we want to display on the map the images with a marker on the point they were taken, we will need to extract their coordinates. This can be achieved via the *EXIF* data embedded in each picture. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8febca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's open the image\n",
    "\n",
    "img_path = images[0] # Using the path we just obtained\n",
    "with open(img_path, 'rb') as src:\n",
    "    img = Image(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce444cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 24.0, 8.57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's access its longitude\n",
    "\n",
    "img.gps_longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bd066",
   "metadata": {},
   "source": [
    "As we can see, the longitude and latitude are in degrees, minutes and seconds. We'll need to use a little function to convert those coordinates to decimal degrees, as well as making the process more streamlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd229c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define a function that simply converts the coordinates to decimal degrees.\n",
    "# We'll have to take into account the orientation (ref), because the result will vary whether it's facing south or west.\n",
    "\n",
    "def converter(coords, ref):\n",
    "    ####################\n",
    "    #Input: coordinates and ref (orientation) of the picture, as expressed by the parser\n",
    "    # Output: if there's coordinates, returns them in decimal degrees.\n",
    "    ####################\n",
    "    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600 # Converting to decimal degrees\n",
    "    if ref == 'S' or ref == 'W':\n",
    "        decimal_degrees = -decimal_degrees # Changing sign if it's facing south or west\n",
    "    return decimal_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ac50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's incorporate it into a new function that will return the coordinates if there's any, and simply\n",
    "# return False if there aren't. This way we can use the same function to know if an image has coordinates\n",
    "# and also retrieve them.\n",
    "\n",
    "def coordinates(image_path):\n",
    "    ####################\n",
    "    #Input: path of an image\n",
    "    # Output: coordinates if there's any, False in any other case\n",
    "    ####################\n",
    "    try:    \n",
    "        def converter(coords, ref):\n",
    "            ####################\n",
    "            #Input: coordinates and ref (orientation) of the picture, as expressed by the parser\n",
    "            # Output: if there's coordinates, returns them in decimal degrees.\n",
    "            ####################\n",
    "            decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600 # Converting to decimal degrees\n",
    "            if ref == 'S' or ref == 'W':\n",
    "                decimal_degrees = -decimal_degrees # Changing sign if it's facing south or west\n",
    "            return decimal_degrees    \n",
    "\n",
    "        with open(img_path, 'rb') as src: # Accessing the image \n",
    "            img = Image(src)    \n",
    "        if img.has_exif:\n",
    "            try:\n",
    "                img.gps_longitude\n",
    "                coords = (converter(img.gps_latitude, # Using our previously defined function\n",
    "                          img.gps_latitude_ref),\n",
    "                          converter(img.gps_longitude,\n",
    "                          img.gps_longitude_ref))\n",
    "            except:\n",
    "                return False # Returning False if the process fails at any point\n",
    "        else:\n",
    "            return False\n",
    "        return coords # Returning the coords\n",
    "    except:\n",
    "        print('Failed to extract image coordinates.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49524363",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232f152",
   "metadata": {},
   "source": [
    "# Flowchart üåä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9add40",
   "metadata": {},
   "source": [
    "The tool behind the **mi Camino** webpage will have two main components: the main loop and the map creator.\n",
    "\n",
    "The main loop will check every *xx* minutes if there's new files (be it gpx or images) in the shared folder, and process them accordingly.\n",
    "\n",
    "The map creator will use the files generated or updated by the main loop to create a new map, which will be displayed in the website.\n",
    "\n",
    "I will now proceed to explain every part in detail, as well as the file system I'll have in place:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3be405",
   "metadata": {},
   "source": [
    "## File system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0364b",
   "metadata": {},
   "source": [
    "The *gpx* files will stay in the original folder, since they only need to be parsed once. All images will be moved to a separate **img** folder, where they will be indexed and accessed by the website (via **Nginx**).\n",
    "\n",
    "Both the main loop and the map creator will use and access several *csv* files, which will mainly act as lightweight dataframe holders. Using *pkl* files was also considered, but it wasn't worth the hassle since read/write speeds aren't critical in our use case. \n",
    "\n",
    "The *csv* files that will be used consist of the following:\n",
    "\n",
    "- **file_log.csv**: contains the original path of every processed file, to prevent duplicates.\n",
    "\n",
    "- **images.csv**: contains both the filepath and coordinates of every picture.\n",
    "\n",
    "- **route.csv**: holds the parsed gpx files of the route I've cycled until that point. Every row is a point, as per gpx standard.\n",
    "\n",
    "- **camino.csv**: the original Camino de Santiago route, to be more specific the french Way. Since every day I'll be traversing part of this route, it will get shorter accordingly. It will always be the original route - the contents of *route.csv*.\n",
    "\n",
    "- **markers.csv**: it will contain information (coordinates, text, html code...) necessary to create map markers when necessary. For example, there will be a marker both at the start/end of the route and at the end of every day's journey, something vital to track overall progress.\n",
    "\n",
    "- **progress.txt**: total progress both in km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db26a4",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc853a8",
   "metadata": {},
   "source": [
    "The main loop will go through the following steps by using two main functions, **img_updater** and **gpx_updater**:\n",
    "\n",
    "**1.** Download all files from the shared folder.\n",
    "\n",
    "**2.** Check filenames against a file log (*file_log.csv*) to detect duplicates.\n",
    "\n",
    "**3.** If there's no new files, the loop will stop at this point. If there are, it will continue.\n",
    "\n",
    "**4.** New files are added to the file log, marking them as processed.\n",
    "\n",
    "**5.** Move images to *img* folder. Store their file paths and image coordinates as a new row in *images.csv*.\n",
    "\n",
    "**6.** Parse gpx files and add the new points to *route.csv*.\n",
    "\n",
    "**7.** Find the closest point to the route for the track in *camino.csv*, which contains the original route from start to finish. Delete the necessary rows so that the remaining route is the original route - distance travelled.\n",
    "\n",
    "**8.** If the date of the parsed *gpx* files is different from the last gpx, a new entry will be created in *markers.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332521ba",
   "metadata": {},
   "source": [
    "## Map creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7c5d5",
   "metadata": {},
   "source": [
    "The map creator will perform the following actions:\n",
    "\n",
    "**1.** Create a new map with bounds (size auto-adjusts).\n",
    "\n",
    "**2.** Plot both routes (*route.csv* and *camino.csv*).\n",
    "\n",
    "**3.** Create and display a marker for every image in *images.csv*.\n",
    "\n",
    "**4.** Create and display a marker for every row in *markers.csv*.\n",
    "\n",
    "**5.** Save the resulting map with the required filename. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e319a17",
   "metadata": {},
   "source": [
    "Now that the basic logic behind our project has been established, let's get to business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416528a",
   "metadata": {},
   "source": [
    "# Development üîß  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f87b3",
   "metadata": {},
   "source": [
    "Let's begin by creating and saving the *csv* files we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e10d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_log = pd.DataFrame(columns=['filepath'])\n",
    "file_log.to_csv('file_log.csv', index=False)\n",
    "\n",
    "images = pd.DataFrame(columns=['filepath', 'coords'])\n",
    "images.to_csv('images.csv', index=False)\n",
    "\n",
    "route = pd.DataFrame(columns=['coords','alt', 'time'])\n",
    "route.to_csv('route.csv', index=False)\n",
    "\n",
    "camino = pd.DataFrame(columns=['coords','alt', 'time'])\n",
    "camino.to_csv('camino.csv', index=False)\n",
    "\n",
    "markers = pd.DataFrame(columns=['coords', 'text', 'html', 'icon', 'color'])\n",
    "markers.to_csv('markers.csv', index=False)\n",
    "\n",
    "progress = pd.DataFrame(columns=['day', 'distance', 'elevation'])\n",
    "progress.to_csv('progress.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cdb71",
   "metadata": {},
   "source": [
    "Now we have the empty *csv* files, which is fine for all of them except *camino.csv*, which should hold the parsed *gpx* file containing the whole route. I won't be following it all the time, but it's a good guideline.\n",
    "\n",
    "In this step we'll parse the *gpx* file and store its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "523280ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'camino.gpx' # The gpx file we need to parse\n",
    "gpx_file = open(filename, 'r', encoding='utf-8') # Opening it, we might encounter encoding issues\n",
    "gpx = gpxpy.parse(gpx_file) #Parsing the file\n",
    "data = gpx.tracks[0].segments[0].points # Extracting all data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519811ec",
   "metadata": {},
   "source": [
    "Now we'll use the latitude/longitude/elevation attributes to extract the coordinates from each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86843ba6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coords = [] #Storing the coordinates\n",
    "alt = [] # Same for the elevation\n",
    "time = []\n",
    "\n",
    "for point in data:\n",
    "    point_coords = (point.latitude,point.longitude) # Obtaining the coordinates from every point\n",
    "    point_alt = point.elevation\n",
    "    point_time = point.time\n",
    "    coords.append(point_coords) #Appending it to the list\n",
    "    alt.append(point_alt)\n",
    "    time.append(point_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a46f3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>alt</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(43.010221, -1.319525)</td>\n",
       "      <td>953.053</td>\n",
       "      <td>2017-04-29 05:41:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(43.009372, -1.319931)</td>\n",
       "      <td>951.804</td>\n",
       "      <td>2017-04-29 05:43:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(43.009108, -1.319748)</td>\n",
       "      <td>950.914</td>\n",
       "      <td>2017-04-29 05:44:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(43.00853, -1.319887)</td>\n",
       "      <td>947.508</td>\n",
       "      <td>2017-04-29 05:45:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(43.007335, -1.319483)</td>\n",
       "      <td>942.526</td>\n",
       "      <td>2017-04-29 05:52:57+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coords      alt                      time\n",
       "0  (43.010221, -1.319525)  953.053 2017-04-29 05:41:48+00:00\n",
       "1  (43.009372, -1.319931)  951.804 2017-04-29 05:43:56+00:00\n",
       "2  (43.009108, -1.319748)  950.914 2017-04-29 05:44:50+00:00\n",
       "3   (43.00853, -1.319887)  947.508 2017-04-29 05:45:16+00:00\n",
       "4  (43.007335, -1.319483)  942.526 2017-04-29 05:52:57+00:00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store those values inside the corresponding csv.\n",
    "\n",
    "df = pd.read_csv('camino.csv')\n",
    "\n",
    "df['coords'] = coords\n",
    "df['alt'] = alt\n",
    "df['time'] = time\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9246bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only thing left to do is save the csv.\n",
    "\n",
    "df.to_csv('camino.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fc0f9",
   "metadata": {},
   "source": [
    "### Downloader function ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c95e75",
   "metadata": {},
   "source": [
    "The first step in the main loop will be downloading the files in the shared folder and checking for new files. To perform this task we'll re-use the code at the beginning of this notebook and create a function that performs the following:\n",
    "\n",
    "- Opens the link to the Google Drive folder in the *txt* file.\n",
    "- Accesses the Google Drive folder and downloads its contents.\n",
    "- Gathers the filenames of the downloaded files and returns them as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdec2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader():\n",
    "    ####################\n",
    "    # Input: none required, but \"url\" must point to a valid GDrive folder\n",
    "    # Output: dictionary containing a list for gpx filenames, same for images\n",
    "    ####################\n",
    "    try:\n",
    "        link = open('download_link.txt','r').readline()\n",
    "        url = link\n",
    "        gdown.download_folder(url, quiet=True, use_cookies=False)\n",
    "\n",
    "        directory = r'C:\\Users\\User\\micamino\\camino' # Out download folder\n",
    "\n",
    "        files = Path(directory).glob('*') # Using all files in the folder as input\n",
    "        files = list(files)\n",
    "\n",
    "        gpx = []\n",
    "        images = []\n",
    "        for file in files:\n",
    "            if '.jpg' in str(file):\n",
    "                images.append(file)\n",
    "            elif '.gpx' in str(file):\n",
    "                gpx.append(file)\n",
    "            else:\n",
    "                pass\n",
    "        print('downloader OK')\n",
    "        return {'gpx': gpx, 'images': images} # The function returns a dictionary of lists, with all filenames\n",
    "    except:\n",
    "        print('downloader FAIL')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "34af0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloader OK\n",
      "[WindowsPath('C:/Users/User/micamino/camino/Primera_etapa_Pirinexus.gpx')]\n",
      "[WindowsPath('C:/Users/User/micamino/camino/PXL_20220629_145708603.jpg')]\n"
     ]
    }
   ],
   "source": [
    "files = downloader() # Running the function we just created\n",
    "\n",
    "print(files['gpx']) # Accessing the images\n",
    "print(files['images']) # Accessing gpx files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03035b48",
   "metadata": {},
   "source": [
    "Once we've downloaded all files, we can be faced by **5** different outcomes:\n",
    "\n",
    "**1. The process fails:** in this case we'll stop the loop until the next iteration.\n",
    "\n",
    "**2. No new files:** same as before.\n",
    "\n",
    "**3. Only new images:** we'll update only the images and generate a new map.\n",
    "\n",
    "**4. Only new gpx:** we'll update only the routes and generate a new map.\n",
    "\n",
    "**5. New gpx and images:** we'll perform the previous 2 steps.\n",
    "\n",
    "Following this logic it makes sense to have 2 separate functions so that each can process images or gpx files, in this case they will be called either individually or in tandem depending on the kind of files to process.\n",
    "\n",
    "Let's create the function that processes images first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d75ae",
   "metadata": {},
   "source": [
    "### Image processing function üì∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839253db",
   "metadata": {},
   "source": [
    "This function must perform the following actions:\n",
    "\n",
    "- Extract coordinates and filename of the new images.\n",
    "- Add that information to the *images.csv* file.\n",
    "- Add the filenames to the file log so that it can track the new files.\n",
    "- Copy the images to the */img* folder.\n",
    "\n",
    "First of all  let's test how can we copy images to the *img* folder. For this purpose we'll be using the library *shutil*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bdcbf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = os.getcwd() + r'/camino/' # Folder where all files are downloaded, takes into account current directory.\n",
    "destination_folder = os.getcwd() + r'/img/' # Output image folder.\n",
    " \n",
    "allfiles = os.listdir(source_folder)\n",
    " \n",
    "for file in allfiles:\n",
    "    if '.jpg' in file: # Moving just jpg images\n",
    "        source = source_folder + file\n",
    "        destination = destination_folder + file\n",
    "        shutil.copy(source , destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9cad2",
   "metadata": {},
   "source": [
    "It's a success! Now let's tie everything together in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8321aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_updater(image_list):\n",
    "    ####################\n",
    "    # Input: dictionary containing the downloaded files (downloader function output).\n",
    "    # Output: extracts image coords, appends coords and path to \"images.csv\", copies images to \"/img\" folder.\n",
    "    #         Also updates the file log with the processed images.\n",
    "    ####################\n",
    "    images = image_list\n",
    "\n",
    "    # Extracting the image coordinates and appending them to \"images.csv\" along with the image path.\n",
    "    df = pd.read_csv('images.csv')\n",
    "\n",
    "    files = pd.read_csv('file_log.csv') # Opening the file log. \n",
    "\n",
    "    def coordinates(image_path):\n",
    "        ####################\n",
    "        #Input: path of an image\n",
    "        # Output: coordinates if there's any, False in any other case\n",
    "        ####################\n",
    "        def converter(coords, ref):\n",
    "            ####################\n",
    "            #Input: coordinates and ref (orientation) of the picture, as expressed by the parser\n",
    "            # Output: if there's coordinates, returns them in decimal degrees.\n",
    "            ####################\n",
    "            decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600 # Converting to decimal degrees\n",
    "            if ref == 'S' or ref == 'W':\n",
    "                decimal_degrees = -decimal_degrees # Changing sign if it's facing south or west\n",
    "            return decimal_degrees    \n",
    "\n",
    "        with open(image_path, 'rb') as src: # Accessing the image \n",
    "            img = Image(src)    \n",
    "        if img.has_exif:\n",
    "            try:\n",
    "                img.gps_longitude\n",
    "                coords = (converter(img.gps_latitude, # Using our previously defined function\n",
    "                          img.gps_latitude_ref),\n",
    "                          converter(img.gps_longitude,\n",
    "                          img.gps_longitude_ref))\n",
    "            except:\n",
    "                return False # Returning False if the process fails at any point\n",
    "        else:\n",
    "            return False\n",
    "        return coords # Returning the coords\n",
    "        print('Failed to extract image coordinates.')    \n",
    "\n",
    "    image_list = [] # This list will hold the dictionaries containing image data.\n",
    "\n",
    "    for image in images:\n",
    "        files = pd.concat([files, pd.DataFrame.from_records({'filepath': [os.path.basename(image)]})])\n",
    "        image_name = os.path.basename(image) # Using the basename attribute to extract file name.\n",
    "        image_coords = coordinates(image) # Extracting coordinates using the previous function.\n",
    "        image_dict = {'filepath': image_name, 'coords': image_coords}\n",
    "        image_list.append(image_dict) # Appending the dictionary.  \n",
    "\n",
    "    # Adding the image to the file log.\n",
    "    files.to_csv('file_log.csv', index=False)\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(image_list)]) # Appending the images to the dataframe.\n",
    "    df.to_csv('images.csv', index=False) # Saving the csv.\n",
    "\n",
    "    # Finally, copying the images to the \"/img\" folder.\n",
    "\n",
    "\n",
    "    source_folder = os.getcwd() + r'/camino/' # Folder where all files are downloaded, takes into account current directory.\n",
    "    destination_folder = os.getcwd() + r'/img/' # Output image folder.\n",
    "\n",
    "    allfiles = os.listdir(source_folder)\n",
    "\n",
    "    for file in allfiles:\n",
    "        if '.jpg' in file: # Moving just jpg images\n",
    "            source = source_folder + file\n",
    "            destination = destination_folder + file\n",
    "            shutil.copy(source , destination)\n",
    "\n",
    "    print('img_updater OK') # Status message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a785a",
   "metadata": {},
   "source": [
    "Since we will need to update *camino.csv* every time that a new gpx file is processed, we'll have to test the procedure first. We will be using haversine distance calculations to find the nearest point between *route.csv* and *camino.csv*, and then cutting the *camino.csv* at the desired point.\n",
    "\n",
    "To perform the testing I've temporarily filled *route.csv* with partial data from *camino.csv*, representing a first day's ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc9145b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading both files\n",
    "camino = pd.read_csv('camino.csv')\n",
    "route = pd.read_csv('route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c426c274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568.3330277885041"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the closest point from the end of the ride (last value of \"route\") to the end of the original route(camino).\n",
    "# For this purpose we'll use the haversine library. Its name is pretty self-explanatory.\n",
    "\n",
    "point_a = eval(route['coords'].iloc[-1]) #We'll need to use eval for the coordinates so that they are read as a tuple.\n",
    "point_b = eval(camino['coords'].iloc[-1])\n",
    "\n",
    "haversine(point_a, point_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9d6b0",
   "metadata": {},
   "source": [
    "### GPX processing function üö≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b99b02",
   "metadata": {},
   "source": [
    "Our function needs to find the minimum distance between the end of *route.csv* and any point of *camino.csv*.\n",
    "It will then shorten the *camino.csv* file accordingly, so that the last point is the closest point to the end of our current route. In other words: the *camino* file will contain **the route that we haven't travelled yet**.\n",
    "\n",
    "**NOTE:** to perform this very same process in other projects I've used vectorized functions applied on an array that contains the coordinates, but since the data volume for this project is *very* low (a single csv at a time) it's not worth the hassle, and I'd rather spend a few more CPU cycles on the calculation than generate potential issues with more dependencies.\n",
    "\n",
    "Let's see what are the requirements of the gpx processing function:\n",
    "\n",
    "- Parse the new gpx file.\n",
    "- Find the closest point to the original route, shorten *camino.csv* accordingly.\n",
    "- Append the new segment to *route.csv*.\n",
    "- Add the filenames to the file log so that it can track the new files.\n",
    "- Update travell progress in *progress.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad461721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_updater(gpx_list):\n",
    "    ####################\n",
    "    # Input: dictionary containing the downloaded files (downloader function output).\n",
    "    # Output: .\n",
    "    ####################\n",
    "    gpx = gpx_list # Loading the new gpx.\n",
    "    distance = int(open('progress.txt','r').readline()) # Reading the current distance (will need updating).\n",
    "\n",
    "    # Adding the new segment to \"route.csv\".\n",
    "\n",
    "    filename = gpx[0] # The gpx file we need to parse\n",
    "    gpx_file = open(filename, 'r', encoding='utf-8') # Opening it, we might encounter encoding issues\n",
    "    gpx = gpxpy.parse(gpx_file) #Parsing the file\n",
    "    data = gpx.tracks[0].segments[0].points # Extracting all data points\n",
    "    segment_distance = int(gpx.length_3d()/1000) # Extracting segment distance.\n",
    "    # Updating the distance.\n",
    "    with open('progress.txt', 'w') as f:\n",
    "        f.write(str(distance + int(segment_distance)))\n",
    "\n",
    "    coords = [] #Storing the coordinates\n",
    "    alt = [] # Same for the elevation\n",
    "    time = []\n",
    "\n",
    "    for point in data:\n",
    "        point_coords = (point.latitude,point.longitude) # Obtaining the coordinates from every point\n",
    "        point_alt = point.elevation\n",
    "        point_time = point.time\n",
    "        coords.append(point_coords) #Appending it to the list\n",
    "        alt.append(point_alt)\n",
    "        time.append(point_time)\n",
    "\n",
    "    # Packing the lists into a dataframe.\n",
    "    zipped = list(zip(coords, alt, time))\n",
    "    segment = pd.DataFrame(zipped, columns=['coords', 'alt', 'time'])\n",
    "\n",
    "    # Adding the segment to the route.\n",
    "    route = pd.read_csv('route.csv')\n",
    "    # Adding the segment.\n",
    "    route = pd.concat([route, segment])\n",
    "    route.to_csv('route.csv', index=False)\n",
    "\n",
    "    # Shortening \"camino.csv\" accordingly.\n",
    "    route = pd.read_csv('route.csv') \n",
    "    camino = pd.read_csv('camino.csv')\n",
    "\n",
    "    min_distance_index = '' # Here we'll hold the index of the minimum distance point.\n",
    "    distance_b = '800' # This value will be replaced every time a lower value is found.\n",
    "\n",
    "    for row in range(len(camino)): # Iterating through the dataframe (painful but necessary).\n",
    "        distance_a = haversine(eval(route['coords'].iloc[-1]), eval(camino['coords'].iloc[row])) # Calculating distance.\n",
    "        if float(distance_a) < float(distance_b): # If the distance is lower than the current one, replace it.\n",
    "            distance_b = distance_a\n",
    "            min_distance_index = row # Also replace the value of the row (index).\n",
    "\n",
    "    camino_shortened = camino[min_distance_index:] # Using the index to crop the csv.\n",
    "    camino_shortened = camino_shortened.reset_index(drop=True) # Resetting the index.\n",
    "    camino_shortened.to_csv('camino.csv', index=False) # Saving the updated camino.csv\n",
    "\n",
    "\n",
    "    # Adding the gpx to the file log.\n",
    "    files = pd.read_csv('file_log.csv') # Opening the file log.\n",
    "    files = pd.concat([files, pd.DataFrame.from_records({'filepath': [os.path.basename(filename)]})])\n",
    "    files.to_csv('file_log.csv', index=False)\n",
    "\n",
    "    print('gpx_updater OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d52d51",
   "metadata": {},
   "source": [
    "### Map creator üó∫Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0545fb",
   "metadata": {},
   "source": [
    "Now that we've processed our new files (be it images or gpx) it's time to create our map. We will use the previously updated *csv* files to create a map via **Folium** and place the following items on it:\n",
    "\n",
    "- Start/end of the route with the distance traveleld/left correspondingly.\n",
    "- All images geolocated.\n",
    "- Plot both the *route* and *camino* files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fb2ad",
   "metadata": {},
   "source": [
    "Now we will create the last of the main functions, the one that generates the necessary markers based on the updated files (*images.csv* and *progress.csv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a5cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_creator():\n",
    "    ####################\n",
    "    # Input: camino, images and progress csv files.\n",
    "    # Output: map with all mecessary markers as well as both routes (camino and route).\n",
    "    ####################\n",
    "    # Loading files.\n",
    "    route = pd.read_csv('route.csv')\n",
    "    camino = pd.read_csv('camino.csv')\n",
    "    images = pd.read_csv('images.csv')\n",
    "    distance = int(open('progress.txt','r').readline()) # Reading the current distance    \n",
    "\n",
    "    marker_list = [] # This list will hold the dictionaries containing the markers.\n",
    "\n",
    "    # Calculating the distance left:\n",
    "    try:\n",
    "        distance_left = (775 - distance) # Total distance - total progress.\n",
    "        if distance_left <= 20:\n",
    "            distance_left = 0\n",
    "    except:\n",
    "        distance_left = 775\n",
    "\n",
    "    # Let's create two markers at the beginning and end of the route which will display the remaining/completed distance.\n",
    "    camino_dict1 = {'coords': '(42.880414, -8.545928)', # This entry is the finish point.\n",
    "                   'text': '', \n",
    "                   'html': '<center><h4><b>Santiago de Compostela</b></h4><a href=\"https://vivecamino.com/img/gal/concha-de-senalizacion-del-camino-de-santiago_7742.jpg\"><img src=\"https://vivecamino.com/img/gal/concha-de-senalizacion-del-camino-de-santiago_7742.jpg\" alt=\"Photo Camino\" style=\"width:101px;height:56px\"></a><h5><b>'+str(distance_left)+'km to go!</p></b></h5></center>',\n",
    "                   'icon': 'glyphicon glyphicon-flag',\n",
    "                   'color': 'red'}\n",
    "    camino_dict2 = {'coords': '(43.010221, -1.319525)', #This one is the beginning.\n",
    "                   'text': '', \n",
    "                   'html': '<center><h4><b>Roncesvalles</b></h4><a href=\"https://upload.wikimedia.org/wikipedia/commons/4/48/Coat_of_Arms_of_Roncesvalles.svg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/4/48/Coat_of_Arms_of_Roncesvalles.svg\" alt=\"Photo Roncesvalles\" style=\"width:80px;height:108px\"></a></center>',\n",
    "                   'icon': 'glyphicon glyphicon-play-circle',\n",
    "                   'color': 'blue'}\n",
    "\n",
    "    # Now we will add a new marker displaying my last known location. To obtain the nearest town we'll be using a \n",
    "    # csv with all spanish towns and their coordinates since we cannot use reverse geocoding (library broken).\n",
    "    towns = pd.read_csv('towns.csv') # This csv contains coordinates of every town in Spain.\n",
    "    current_location = eval(route['coords'].iloc[-1]) # Coords of the last known location.\n",
    "\n",
    "    town = '' # Here we'll hold the closest town..\n",
    "    province = '' # ..along with its province.\n",
    "    distance_b = '50' # Values over 50km will be simply discarded.\n",
    "\n",
    "    for row in range(len(towns)): # Iterating through all towns to locate the closest one.\n",
    "        distance_a = haversine(current_location, eval(towns['coords'].iloc[row])) \n",
    "        if float(distance_a) < float(distance_b): \n",
    "            distance_b = distance_a\n",
    "            town = towns['name'].iloc[row] # Saving the closest town.\n",
    "            province = towns['province'].iloc[row] # Along with its province.\n",
    "\n",
    "    # Creating the new marker.\n",
    "    location_dict = {'coords': str(current_location), #This one is the beginning.\n",
    "                   'text': '', \n",
    "                   'html': '<center><h5><b>'+town+', '+province+'<p style=\"color:blue;\">'+str(distance)+'km</p></h5></b></center>',\n",
    "                   'icon': 'glyphicon glyphicon-map-marker',\n",
    "                   'color': 'green'}\n",
    "\n",
    "    # Adding the new markers to the marker list.\n",
    "    marker_list.append(camino_dict1)\n",
    "    marker_list.append(camino_dict2)\n",
    "    marker_list.append(location_dict)\n",
    "\n",
    "\n",
    "    # Adding the images.\n",
    "    for i in range(len(images)):\n",
    "        image_dict = {'coords': images['coords'].iloc[i],\n",
    "                      'text': '',\n",
    "                      'html': '<a href=\"http://www.fresquito.es/micamino/map.html\"><img src='+'http://www.fresquito.es/micamino/img/'+images['filepath'].iloc[i]+' alt=\"Photo placeholder\" style=\"width:101px;height:134px\"></a>',\n",
    "                      'icon': 'glyphicon glyphicon-camera',\n",
    "                      'color': 'black'}\n",
    "        marker_list.append(image_dict) # Appending the new marker (image).\n",
    "\n",
    "    # Now that we have all the markers, let's store them in a dataframe.\n",
    "    markers = pd.DataFrame(marker_list)\n",
    "\n",
    "    # Creating the empty map.\n",
    "    temp_map = map = folium.Map()\n",
    "    temp_map.fit_bounds([(42.864165, -9.058972), (42.829900, -1.035834)]) # Adjusting size.\n",
    "\n",
    "    # Adding every marker to the map.\n",
    "    for i in range(len(markers)):\n",
    "        try:\n",
    "            folium.Marker(location= eval(markers['coords'].iloc[i]), \n",
    "                              popup= markers['html'].iloc[i],\n",
    "                              icon=folium.Icon(color=markers['color'].iloc[i],icon=markers['icon'].iloc[i])\n",
    "                              ).add_to(temp_map) # Creating a marker out of every entry.\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Plotting both routes in the map (route.csv and camino.csv). Since the plotline function of Folium needs \n",
    "    # coordinates as tuples and they are stored as strings in our csv files, we'll need to perform a quick transformation.\n",
    "    route_clean = []\n",
    "    for i in range(len(route)):\n",
    "        route_clean.append(eval(route['coords'].iloc[i])) # Adding every point as a tuple by using eval.\n",
    "\n",
    "    # Performing the same action for the camino.\n",
    "    camino_clean = []\n",
    "    for i in range(len(camino)):\n",
    "        camino_clean.append(eval(camino['coords'].iloc[i]))\n",
    "\n",
    "    # Now we can plot both lines on the map. They will have separate colors and styles to differentiate them easily.\n",
    "    folium.PolyLine(route_clean, color='blue', weight=4, opacity=0.8).add_to(temp_map) # Adding the route as a polyline.\n",
    "    folium.PolyLine(camino_clean, color='red', weight=4, opacity=0.8, dash_array='2,7').add_to(temp_map) # Same action for camino.\n",
    "\n",
    "    # Saving the map.\n",
    "    map.save(outfile= \"map.html\")\n",
    "    print('map_creator OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea480b",
   "metadata": {},
   "source": [
    "## Creating the main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da8bad",
   "metadata": {},
   "source": [
    "Now that all functions are ready and tested it's time to combine them into a loop, so that it can be easily called by a cronjob. It will need to perform the following:\n",
    "\n",
    "- Download all files.\n",
    "- Check for new files.\n",
    "- If new files are detected, run the necessary functions and create a new map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1917cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    files = downloader() # Downloading files.\n",
    "\n",
    "    file_log = pd.read_csv('file_log.csv') # Loading current files.\n",
    "\n",
    "    # Creating a list with the current files.\n",
    "    current_files = file_log['filepath'].tolist()\n",
    "\n",
    "    gpx_list = [] # Holding the new files (if any).\n",
    "    img_list = []\n",
    "\n",
    "    if files != False:\n",
    "        file_log = pd.read_csv('file_log.csv')\n",
    "        if (len(files['gpx']) != 0) or (len(files['images']) != 0): # If there's files in the downloaded content, continue.\n",
    "            for gpx_file in files['gpx']:\n",
    "                if os.path.basename(gpx_file) not in current_files: # Checking for non-duplicated gpx.\n",
    "                    gpx_list.append(gpx_file) # Adding the file to the list.\n",
    "                else:\n",
    "                    pass\n",
    "            for img_file in files['images']: # Checking the images similarly.\n",
    "                if os.path.basename(img_file) not in current_files:\n",
    "                    img_list.append(img_file)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        # Now we'll need to call the corresponding functions depending on the previous outcome:\n",
    "        if (len(gpx_list) != 0) and (len(img_list) != 0):\n",
    "            gpx_updater(gpx_list)\n",
    "            img_updater(img_list)\n",
    "            map_creator()\n",
    "        elif len(gpx_list) != 0:\n",
    "            gpx_updater(gpx_list)\n",
    "            map_creator()\n",
    "        elif len(img_list) != 0:\n",
    "            img_updater(img_list)\n",
    "            map_creator()\n",
    "        else:\n",
    "            print('No new files.')\n",
    "            pass \n",
    "    print('main_loop OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc1195",
   "metadata": {},
   "source": [
    " Now it's simply a matter of calling the main loop every X minutes. This loop works for my testing environment (Windows), but some parts have had to be modified to run natively on a **Raspberry Pi 4**, my home server. Those modifications are outside the scope of this notebook.\n",
    " \n",
    " If you've read this far, I hope you enjoyed this project as much as I did, you can find the live version below üòä\n",
    " \n",
    " \n",
    " http://www.fresquito.es/micamino/map.html\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
